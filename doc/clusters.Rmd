---
title: "Comparing network clusters from tragula with expert-curated clusters"
author: "Art Poon"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_knit$set(root.dir="~/git/tragula")
```

Load information about department faculty, where I have manually added annotations on the membership of faculty members in 12 areas of research.  These areas were identified through questionnaires and manual assessment of clusters.
```{r}
palm <- read.csv("data/palm.tsv", sep='\t')
for (i in 5:ncol(palm)) {
  palm[is.na(palm[,i]), i] <- FALSE
}
```

Next, we'll load the Wasserstein distance matrix that was pre-computed for the main README document.
```{r warning=FALSE, message=FALSE}
load("results/palm_wdist.RData")

# make sure labels match the distance matrix
palm$filename <- paste(palm$lastname, palm$forename, sep="_")
palm$filename <- gsub(" ", "_", palm$filename)
palm$label <- paste(substr(palm$forename, 1, 1), 
                    substr(gsub("[ -]", "", palm$lastname), 1, 4), sep="")
idx <- match(attr(wdist, "Labels"), palm$filename)
labels <- palm$label[idx]
```

Display the manual clustering of members into areas of research:
```{r fig.width=5, fig.height=5, dpi=150, out.width="66%"}
source("scripts/visualize.R")
g <- make.knn(wdist, k=3)

areas <- apply(palm[,5:16], 2, function(x) {
  palm$filename[which(x)]
})

par(mar=rep(0,4))
plot(g, mark.groups=areas, vertex.label=labels, vertex.label.cex=0.7, 
     vertex.shape="none", edge.width=2, edge.arrow.mode='-')
```


Let's start with the original network community detection analysis of these data:
```{r fig.width=5, fig.height=5, dpi=150, out.width="66%"}
require(igraph, quietly=TRUE)
cl <- cluster_louvain(g)
par(mar=rep(0, 4))
plot(g, mark.groups=cl, vertex.shape="none", vertex.label=labels, 
     vertex.label.cex=0.7, vertex.size=6, 
     edge.width=2, edge.arrow.mode='-')
```

A significant issue is that there are an enormous number of ways to cluster these data, not only by varying the criteria for drawing edges (distance threshold and maximum in-degree), but also by changing the community detection method applied to the graph:
```{r fig.width=5, fig.height=5, dpi=150, out.width="66%"}
res <- cluster_label_prop(g)
#sum(sapply(igraph::groups(res), length))
par(mar=rep(0, 4))
plot(g, mark.groups=res, vertex.shape="none", vertex.label=labels,
     vertex.label.cex=0.7, vertex.size=6,
     edge.width=2, edge.arrow.mode='-')
```

The clique percolation algorithm allows for overlapping communities.
In the following plot, nodes that are assigned to two or more communities are labelled with multiple colours:
```{r fig.width=5, fig.height=5, dpi=150, out.width="66%"}
require(CliquePercolation, quietly = TRUE)
require(qgraph, quietly=TRUE)
require(ggfree)
W <- getWmat(g)
row.names(W) <- colnames(W) <- labels
qg <- qgraph(W)
cp <- cpAlgorithm(qg, k=3, method='unweighted')
m <- length(cp$list.of.communities.labels)
pal <- gg.rainbow(m, l=80)
col.net <- cpColoredGraph(W, list.of.communities = cp$list.of.communities.labels, 
                          own.colors=pal)
```


## Measuring concordance
Let's calculate the adjusted Rand index for concordance of partitions with potentially overlapping communities (omega index, Collins and Dent 1988):
$$\omega(C_1, C_2) = \frac{\omega_u(C_1, C_2) - \omega_e(C_1, C_2)}{1-\omega_e(C_1, C_2)}$$
where $\omega_u$ is the unadjusted omega index and $\omega_e$ is the omega index expected by chance.
This implies that $\omega_u$ has a maximum of $1$ and a minimum of $\omega_e$.

The unadjusted omega index is calculated as:
$$\omega_u(C_1, C_2) = \frac{1}{M} \sum_{j=0}^{\max(K_1, K_2)} | t_j(C_1) \cap t_j(C_2)|$$
where $M$ is the total number of node pairs, $K_i$ is the number of communities in partition $C_i$, and $t_j(C)$ is set of node pairs that appear in 8exactly $j$ clusters in partition $C$ (Xie, Kelley and Szymanski, https://arxiv.org/abs/1110.5813v4).
(Xie *et al.* refer to partitions as "covers".)
The expected value is calculated as:
$$\omega_e(C_1, C_2) = \frac{1}{M^2} \sum_{j=0}^{\max(K_1, K_2)} |t_j(C_1)| \cdot |t_j(C_2)|$$
This method examines pairs of nodes because any one community does not carry a label that would enable us to evaluate the concordance of two partitions.
In other words, we cannot check whether node A is in the same community in both $C_1$ and $C_2$.
Belonging to the *same* community as a second node B *does* make it possible to make this comparison.

We can implement this in R with a function taking two lists of community memberships per node:
```{r}
require(combinat, quietly=TRUE)

#' Returns all pairs of nodes with same cluster memberships
#' @param nodes:  character, labels for all nodes
#' @param cvr:  list, character vectors of labels for each cluster
#' @return list, matched node pairs by number of clusters
get.pairs <- function(nodes, cvr) {
  # which communities does each node appear in?
  membership <- lapply(nodes, function(node) {
    which(sapply(cvr, function(x) is.element(node, x)))
    })
  names(membership) <- nodes
  
  pairs <- list()
  cmx <- combinat::combn2(nodes)
  for (i in 1:nrow(cmx)) {
    u <- cmx[i, 1]
    v <- cmx[i, 2]
    if (u > v) { temp <- v; v <- u; u <- temp }
    key <- paste(u, v, sep=" ")
    n <- length(intersect(membership[[u]], membership[[v]]))
    pairs[[key]] <- n
  }
  pairs
}

#' Calculates an clustering agreement index 
omega <- function(nodes, c1, c2) {
  pairs1 <- get.pairs(nodes, c1)
  pairs2 <- get.pairs(nodes, c2)
  M <- choose(length(nodes), 2)
  
  # observed value
  omega.u <- 0
  for (key in names(pairs1)) {
    if (pairs1[[key]] == pairs2[[key]]) {
      omega.u <- omega.u + 1
    }
  }
  omega.u <- omega.u / M
  
  # expected value
  n1 <- as.integer(pairs1)
  n2 <- as.integer(pairs2)
  K <- max(c(n1, n2))
  omega.e <- sum(sapply(0:K, function(j) {
    sum(n1==j) * sum(n2==j)
  })) / (M*M)
  return ((omega.u-omega.e) / (1-omega.e))
}
```


This cluster agreement index is quite low for different clustering methods relative to the manual clustering (research areas):
```{r}
c1 <- lapply(5:16, function(i) palm$label[which(palm[,i])])
omega(labels, c1, c1)  # this should be one

# clique percolation
c2 <- lapply(cp$list.of.communities.numbers, function(i) labels[i])
omega(labels, c1, c2)

# Louvain clustering
c3 <- split(labels, cl$membership)
omega(labels, c1, c3)

# label propagation
c4 <- split(labels, res$membership)
omega(labels, c1, c4)

# how well do clustering methods agree with each other?
omega(labels, c2, c3)
omega(labels, c2, c4)
omega(labels, c3, c4)
```

